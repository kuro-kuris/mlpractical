{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please don't edit this cell!**\n",
    "\n",
    "# Marks and Feedback\n",
    "\n",
    "**Total Marks:**   XX/100\n",
    "\n",
    "**Overall comments:**\n",
    "\n",
    "\n",
    "## Part 1. Investigations into Neural Networks (35 marks)\n",
    "\n",
    "* **Task 1**:   *Experiments with learning rate schedules* - XX/5\n",
    "    * learning rate schedulers implemented\n",
    "    * experiments carried out\n",
    "    * further comments\n",
    "\n",
    "\n",
    "* **Task 2**:   *Experiments with regularisation* - XX/5\n",
    "    * L1 experiments\n",
    "    * L2 experiments\n",
    "    * dropout experiments\n",
    "    * annealed dropout implmented\n",
    "    * further experiments carried out\n",
    "    * further comments\n",
    "    \n",
    "\n",
    "* **Task 3**:   *Experiments with pretraining* - XX/15\n",
    "    * autoencoder pretraining implemented\n",
    "    * denoising autoencoder pretraining implemented\n",
    "    * CE layer-by-layer pretraining implemented\n",
    "    * experiments\n",
    "    * further comments\n",
    "\n",
    "\n",
    "* **Task 4**:   *Experiments with data augmentation* - XX/5\n",
    "    * training data augmneted using noise, rotation, ...\n",
    "    * any further augmnetations\n",
    "    * experiments \n",
    "    * further comments\n",
    "\n",
    "\n",
    "* **Task 5**:   *State of the art* - XX/5\n",
    "    * motivation for systems constructed\n",
    "    * experiments\n",
    "    * accuracy of best system\n",
    "    * further comments\n",
    "\n",
    "\n",
    "\n",
    "## Part 2. Convolutional Neural Networks (55 marks)\n",
    "\n",
    "* **Task 6**:   *Implement convolutional layer* - XX/20\n",
    "    * linear conv layer\n",
    "    * sigmoid conv layer\n",
    "    * relu conv layer\n",
    "    * any checks for correctness\n",
    "    * loop-based or vectorised implementations\n",
    "    * timing comparisons\n",
    "\n",
    "\n",
    "* **Task 7**:   *Implement maxpooling layer* - XX/10\n",
    "    * implementation of non-overlapping pooling\n",
    "    * generic implementation\n",
    "    * any checks for correctness\n",
    "\n",
    "\n",
    "* **Task 8**:   *Experiments with convolutional networks* - XX/25\n",
    "    * 1 conv layer (1 fmap)\n",
    "    * 1 conv layer (5 fmaps)\n",
    "    * 2 conv layers\n",
    "    * further experiments\n",
    "\n",
    "\n",
    "\n",
    "## Presentation (10 marks)\n",
    "\n",
    "* ** Marks:**   XX/10\n",
    "    * Concise description of each system constructed\n",
    "    * Experiment design and motivations for different systems\n",
    "    * Presentation of results - graphs, tables, diagrams\n",
    "    * Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework #2\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "## Previous Tutorials\n",
    "\n",
    "Before starting this coursework make sure that you have completed the following labs:\n",
    "\n",
    "* [04_Regularisation.ipynb](https://github.com/CSTR-Edinburgh/mlpractical/blob/master/04_Regularisation.ipynb) - regularising the model\n",
    "* [05_Transfer_functions.ipynb](https://github.com/CSTR-Edinburgh/mlpractical/blob/master/05_Transfer_functions.ipynb) - building and training different activation functions\n",
    "* [06_MLP_Coursework2_Introduction.ipynb](https://github.com/CSTR-Edinburgh/mlpractical/blob/master/06_MLP_Coursework2_Introduction.ipynb) - Notes on numpy and tensors\n",
    "\n",
    "\n",
    "## Submission\n",
    "**Submission Deadline:  Thursday 14 January 2016, 16:00** \n",
    "\n",
    "Submit the coursework as an ipython notebook file, using the `submit` command in the terminal on a DICE machine. If your file is `06_MLP_Coursework1.ipynb` then you would enter:\n",
    "\n",
    "`submit mlp 2 06_MLP_Coursework1.ipynb` \n",
    "\n",
    "where `mlp 2` indicates this is the second coursework of MLP.\n",
    "\n",
    "After submitting, you should receive an email of acknowledgment from the system confirming that your submission has been received successfully. Keep the email as evidence of your coursework submission.\n",
    "\n",
    "**Please make sure you submit a single `ipynb` file (and nothing else)!**\n",
    "\n",
    "**Submission Deadline:  Thursday 14 January 2016, 16:00** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "Please enter your student number and the date in the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MLP Coursework 2\n",
    "#Student number: s1210107\n",
    "#Date: 16/12/2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Investigations into Neural Networks (35 marks)\n",
    "\n",
    "In this part you are may choose exactly what you implement. However, you are expected to express your motivations, observations, and findings in a clear and cohesive way. Try to make it clear why you decided to do certain things. Use graphs and/or tables of results to show trends and other characteristics you think are important. \n",
    "\n",
    "For example, in Task 1 you could experiment with different schedulers in order to compare their convergence properties. In Task 2 you could look into (and visualise) what happens to weights when applying L1 and/or L2 regularisation when training. For instance, you could create sorted histograms of weight magnitudes in in each layer, etc..\n",
    "\n",
    "**Before submission, please collapse all the log entries into smaller boxes (by clicking on the bar on the left hand side)**\n",
    "\n",
    "### Task 1 - Experiments with learning rate schedules (5 marks)\n",
    "\n",
    "Investigate the effect of learning rate schedules on training and accuracy.  Implement at least one additional learning rate scheduler mentioned in the lectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.624. Accuracy is 8.60%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.554. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 3.053. Accuracy is 58.00%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.600. Accuracy is 81.41%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 1 seconds. Training speed 1100 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.518. Accuracy is 83.50%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.497. Accuracy is 85.12%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 1 seconds. Training speed 1112 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.324. Accuracy is 91.00%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.458. Accuracy is 85.38%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 1 seconds. Training speed 1100 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.277. Accuracy is 92.10%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.389. Accuracy is 88.80%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 2 seconds. Training speed 944 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.171. Accuracy is 95.40%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.389. Accuracy is 89.03%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 2 seconds. Training speed 972 pps. Validation speed 16395 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.138. Accuracy is 96.90%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.376. Accuracy is 89.26%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 2 seconds. Training speed 910 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.098. Accuracy is 98.00%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.381. Accuracy is 89.46%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 2 seconds. Training speed 1065 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.071. Accuracy is 99.00%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.379. Accuracy is 89.73%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 1 seconds. Training speed 1112 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.056. Accuracy is 99.20%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.388. Accuracy is 89.77%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.042. Accuracy is 99.40%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.388. Accuracy is 90.06%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 1 seconds. Training speed 1088 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.033. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.429. Accuracy is 89.03%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 2 seconds. Training speed 1076 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.029. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.403. Accuracy is 89.59%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 2 seconds. Training speed 1065 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.022. Accuracy is 99.80%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.409. Accuracy is 89.73%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 2 seconds. Training speed 1065 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.018. Accuracy is 99.90%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.417. Accuracy is 89.73%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 1 seconds. Training speed 1100 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.015. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.406. Accuracy is 90.08%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 1 seconds. Training speed 1100 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.013. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.418. Accuracy is 89.95%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 1 seconds. Training speed 1088 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.011. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.417. Accuracy is 90.03%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 1 seconds. Training speed 1088 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.011. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.420. Accuracy is 90.10%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.009. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.423. Accuracy is 90.24%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 2 seconds. Training speed 1054 pps. Validation speed 16951 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.008. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.425. Accuracy is 90.07%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 2 seconds. Training speed 991 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.008. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.429. Accuracy is 90.05%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 1 seconds. Training speed 1100 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.007. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.429. Accuracy is 90.28%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 1 seconds. Training speed 1112 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.007. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.430. Accuracy is 90.22%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 1 seconds. Training speed 1112 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.433. Accuracy is 90.24%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.436. Accuracy is 90.35%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 1 seconds. Training speed 1112 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.439. Accuracy is 90.23%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 1 seconds. Training speed 1100 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.441. Accuracy is 90.28%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 2 seconds. Training speed 1088 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.441. Accuracy is 90.32%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 2 seconds. Training speed 1065 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.443. Accuracy is 90.29%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 1 seconds. Training speed 1088 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.448. Accuracy is 90.24%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 2 seconds. Training speed 1076 pps. Validation speed 17546 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 89.44 %, cost (ce) is 0.457\n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.867. Accuracy is 8.50%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.795. Accuracy is 10.85%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.988. Accuracy is 56.70%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.691. Accuracy is 78.06%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 1 seconds. Training speed 1112 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.506. Accuracy is 84.40%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.422. Accuracy is 87.41%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 1 seconds. Training speed 1112 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.323. Accuracy is 90.60%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.385. Accuracy is 88.36%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 1 seconds. Training speed 1125 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.250. Accuracy is 92.10%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.413. Accuracy is 87.09%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 1 seconds. Training speed 1112 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.167. Accuracy is 95.70%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.366. Accuracy is 89.50%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.127. Accuracy is 96.90%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.433. Accuracy is 87.95%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 2 seconds. Training speed 1065 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.099. Accuracy is 97.90%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.398. Accuracy is 88.90%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.073. Accuracy is 98.40%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.376. Accuracy is 89.71%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 1 seconds. Training speed 1100 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.054. Accuracy is 99.40%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.366. Accuracy is 90.22%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 1 seconds. Training speed 1100 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.038. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.372. Accuracy is 90.22%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 1 seconds. Training speed 1100 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.034. Accuracy is 99.50%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.386. Accuracy is 89.87%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 1 seconds. Training speed 1100 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.025. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.388. Accuracy is 90.00%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.019. Accuracy is 99.90%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.390. Accuracy is 90.25%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 1 seconds. Training speed 1112 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.016. Accuracy is 99.80%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.399. Accuracy is 90.02%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 1 seconds. Training speed 1088 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.015. Accuracy is 99.90%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.397. Accuracy is 90.21%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 1 seconds. Training speed 1112 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.012. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.404. Accuracy is 90.27%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 1 seconds. Training speed 1076 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.011. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.406. Accuracy is 90.37%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 2 seconds. Training speed 1076 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.010. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.412. Accuracy is 90.08%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 1 seconds. Training speed 1112 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.009. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.409. Accuracy is 90.25%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 1 seconds. Training speed 1088 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.009. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.416. Accuracy is 90.16%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 1 seconds. Training speed 1100 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.008. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.418. Accuracy is 90.21%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 1 seconds. Training speed 1125 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.007. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.417. Accuracy is 90.26%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.007. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.420. Accuracy is 90.28%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 1 seconds. Training speed 1088 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.423. Accuracy is 90.31%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 2 seconds. Training speed 1054 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.425. Accuracy is 90.26%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 1 seconds. Training speed 1112 pps. Validation speed 18520 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.427. Accuracy is 90.24%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 1 seconds. Training speed 1100 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.429. Accuracy is 90.23%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 1 seconds. Training speed 1112 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.431. Accuracy is 90.30%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 1 seconds. Training speed 1125 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.432. Accuracy is 90.19%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 1 seconds. Training speed 1125 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.434. Accuracy is 90.20%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 1 seconds. Training speed 1088 pps. Validation speed 17859 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 89.49 %, cost (ce) is 0.439\n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 2.410. Accuracy is 11.40%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 2.392. Accuracy is 10.00%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 2.879. Accuracy is 58.60%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 0.758. Accuracy is 71.13%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 0.499. Accuracy is 83.90%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 0.483. Accuracy is 84.89%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 0.362. Accuracy is 88.70%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 0.447. Accuracy is 86.42%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 1 seconds. Training speed 1125 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 0.244. Accuracy is 92.90%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 0.444. Accuracy is 86.95%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 1 seconds. Training speed 1125 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 0.164. Accuracy is 95.70%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 0.409. Accuracy is 88.44%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 1 seconds. Training speed 1125 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 0.126. Accuracy is 97.20%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 0.394. Accuracy is 88.91%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 1 seconds. Training speed 1088 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 0.085. Accuracy is 98.30%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 0.412. Accuracy is 88.73%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 2 seconds. Training speed 1054 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 0.067. Accuracy is 99.00%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 0.379. Accuracy is 89.92%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 1 seconds. Training speed 1100 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 0.050. Accuracy is 99.20%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 0.418. Accuracy is 88.74%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 1 seconds. Training speed 1112 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 0.040. Accuracy is 99.50%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 0.467. Accuracy is 87.64%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 1 seconds. Training speed 1100 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 0.031. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 0.394. Accuracy is 89.79%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 1 seconds. Training speed 1100 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 0.027. Accuracy is 99.80%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 0.402. Accuracy is 89.71%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 1 seconds. Training speed 1088 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 0.020. Accuracy is 99.80%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 0.401. Accuracy is 89.86%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 0.016. Accuracy is 99.90%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 0.412. Accuracy is 89.76%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 1 seconds. Training speed 1100 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 0.014. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 0.412. Accuracy is 89.91%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 1 seconds. Training speed 1112 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 0.012. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 0.424. Accuracy is 89.58%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 0.011. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 0.420. Accuracy is 89.77%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 2 seconds. Training speed 1065 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 0.010. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 0.420. Accuracy is 89.92%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 1 seconds. Training speed 1088 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 0.009. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 0.427. Accuracy is 89.97%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 1 seconds. Training speed 1100 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 0.009. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 0.425. Accuracy is 89.98%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 1 seconds. Training speed 1100 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 0.008. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 0.432. Accuracy is 89.78%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 2 seconds. Training speed 1065 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 0.007. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 0.432. Accuracy is 89.99%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 0.007. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 0.433. Accuracy is 89.96%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 1 seconds. Training speed 1125 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 0.434. Accuracy is 89.98%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 2 seconds. Training speed 1054 pps. Validation speed 16395 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 0.439. Accuracy is 90.09%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 2 seconds. Training speed 1011 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 0.006. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 0.442. Accuracy is 89.78%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 2 seconds. Training speed 1001 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 0.443. Accuracy is 89.92%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 1 seconds. Training speed 1112 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 0.444. Accuracy is 89.90%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 2 seconds. Training speed 1011 pps. Validation speed 16951 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 0.444. Accuracy is 89.95%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 2 seconds. Training speed 991 pps. Validation speed 16951 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 0.005. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 0.449. Accuracy is 90.06%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 2 seconds. Training speed 1043 pps. Validation speed 17243 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 89.43 %, cost (ce) is 0.456\n"
     ]
    }
   ],
   "source": [
    "#load the corresponding code here, and also attach scripts that run the experiments ()\n",
    "\n",
    "import numpy\n",
    "import logging\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=10, max_num_batches=100, randomize=True)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "training_set_size = train_dp.batch_size * train_dp._max_num_batches\n",
    "\n",
    "#Baseline experiment\n",
    "\n",
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateFixed, LearningRateExponential, LearningRateReciprocal\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "learning_rate = 0.5\n",
    "max_epochs = 30\n",
    "cost = CECost()\n",
    "\n",
    "lr_fixed = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "lr_exponential = LearningRateExponential(learning_rate=learning_rate, max_epochs=max_epochs, train_set_size=training_set_size)\n",
    "lr_reciprocal = LearningRateReciprocal(learning_rate=learning_rate, max_epochs=max_epochs, train_set_size=training_set_size)\n",
    "\n",
    "lr_schedulers = [lr_fixed,lr_exponential,lr_reciprocal]\n",
    "\n",
    "\n",
    "stats = []\n",
    "for lr_scheduler in lr_schedulers:\n",
    "\n",
    "    layer = 1\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "    \n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "    model.add_layer(Sigmoid(idim=784, odim=nhid, irange=0.2, rng=rng))\n",
    "    for i in xrange(1, layer):\n",
    "        logger.info(\"Stacking hidden layer (%s)\" % str(i+1))\n",
    "        model.add_layer(Sigmoid(idim=nhid, odim=nhid, irange=0.2, rng=rng))\n",
    "    model.add_layer(Softmax(idim=nhid, odim=10, rng=rng))\n",
    "\n",
    "    # define the optimiser, here stochasitc gradient descent\n",
    "    # with fixed learning rate and max_epochs\n",
    "    lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler)\n",
    "\n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "    \n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# arranging the data for plotting\n",
    "test_results = [stat[2] for stat in stats]\n",
    "test_ce_costs = [test_result[0] for test_result in test_results]\n",
    "test_accuracies = [test_result[1] for test_result in test_results]\n",
    "\n",
    "fixed_training_ce_costs = [test_result[1] for test_result in stats[0][1]]\n",
    "exponential_training_ce_costs = [test_result[1] for test_result in stats[1][1]]\n",
    "reciprocal_training_ce_costs = [test_result[1] for test_result in stats[2][1]]\n",
    "\n",
    "fixed_training_accuracies = [test_result[1] for test_result in stats[0][1]]\n",
    "exponential_training_accuracies = [test_result[1] for test_result in stats[1][1]]\n",
    "reciprocal_training_accuracies = [test_result[1] for test_result in stats[2][1]]\n",
    "\n",
    "epochs = xrange(0,31)\n",
    "names = ['fixed','exponential','reciprocal']\n",
    "\n",
    "# training plot\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(fixed_training_accuracies, epochs, label=\"fixed\")\n",
    "plt.plot(exponential_training_accuracies, epochs, label=\"exponential\")\n",
    "plt.plot(reciprocal_training_accuracies, epochs, label=\"reciprocal\")\n",
    "\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Training accuracy (%)')\n",
    "plt.title('Fixed, exponential, and reciprocal learning rate scheduler test accuracy')\n",
    "plt.legend(loc='left')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.savefig(\"pictures/test.png\")\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "width = .25\n",
    "ind = numpy.arange(len(test_accuracies))\n",
    "plt.bar(ind, test_accuracies)\n",
    "plt.xticks(ind + width / 2, names)\n",
    "\n",
    "plt.xlabel('Different learning rate schedulers')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Fixed, exponential, and reciprocal learning rate scheduler test accuracy')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"pictures/test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Experiments with regularisers (5 marks)\n",
    "\n",
    "Investigate the effect of different regularisation approaches (L1, L2, dropout).  Implement the annealing dropout scheduler (mentioned in lecture 5). Do some further investigations and experiments with model structures (and regularisers) of your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialising data providers...\n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 65.717. Accuracy is 8.60%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 65.646. Accuracy is 9.84%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 63.716. Accuracy is 57.50%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 61.280. Accuracy is 80.27%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 2 seconds. Training speed 705 pps. Validation speed 16668 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 58.420. Accuracy is 82.70%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 58.393. Accuracy is 84.29%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 2 seconds. Training speed 695 pps. Validation speed 16951 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 55.427. Accuracy is 90.50%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 55.567. Accuracy is 84.00%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 2 seconds. Training speed 700 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 52.719. Accuracy is 89.30%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 52.789. Accuracy is 87.89%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 2 seconds. Training speed 690 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 49.920. Accuracy is 93.80%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 50.102. Accuracy is 88.50%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 2 seconds. Training speed 686 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 47.290. Accuracy is 94.10%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 47.482. Accuracy is 88.58%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 2 seconds. Training speed 736 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 44.752. Accuracy is 95.70%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 44.997. Accuracy is 88.22%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 2 seconds. Training speed 690 pps. Validation speed 15875 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 42.246. Accuracy is 96.70%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 42.499. Accuracy is 88.92%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 2 seconds. Training speed 646 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 39.819. Accuracy is 98.00%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 40.142. Accuracy is 88.10%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 2 seconds. Training speed 725 pps. Validation speed 16951 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 37.520. Accuracy is 97.80%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 37.806. Accuracy is 89.30%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 2 seconds. Training speed 672 pps. Validation speed 16131 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 35.260. Accuracy is 97.30%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 35.627. Accuracy is 86.94%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 2 seconds. Training speed 676 pps. Validation speed 16668 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 33.193. Accuracy is 96.40%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 33.486. Accuracy is 88.61%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 2 seconds. Training speed 736 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 31.032. Accuracy is 98.50%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 31.478. Accuracy is 85.35%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 2 seconds. Training speed 770 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 29.154. Accuracy is 97.60%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 29.785. Accuracy is 80.63%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 2 seconds. Training speed 764 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 27.144. Accuracy is 97.80%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 27.483. Accuracy is 88.44%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 2 seconds. Training speed 770 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 25.273. Accuracy is 98.50%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 25.647. Accuracy is 87.94%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 2 seconds. Training speed 764 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 23.551. Accuracy is 97.90%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 23.912. Accuracy is 88.05%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 2 seconds. Training speed 770 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 21.967. Accuracy is 97.40%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 22.394. Accuracy is 85.38%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 2 seconds. Training speed 770 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 20.346. Accuracy is 98.70%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 20.716. Accuracy is 87.98%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 2 seconds. Training speed 764 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 18.746. Accuracy is 98.80%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 19.097. Accuracy is 88.80%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 2 seconds. Training speed 770 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 17.430. Accuracy is 97.70%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 17.898. Accuracy is 85.70%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 2 seconds. Training speed 764 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 16.590. Accuracy is 96.70%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 18.871. Accuracy is 79.13%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 2 seconds. Training speed 770 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 15.236. Accuracy is 95.40%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 15.451. Accuracy is 88.64%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 2 seconds. Training speed 782 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 13.771. Accuracy is 98.80%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 14.126. Accuracy is 88.57%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 2 seconds. Training speed 770 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 12.776. Accuracy is 97.30%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 13.126. Accuracy is 88.55%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 2 seconds. Training speed 776 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 11.787. Accuracy is 97.60%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 12.209. Accuracy is 86.19%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 2 seconds. Training speed 770 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 11.077. Accuracy is 94.30%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 11.452. Accuracy is 86.05%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 2 seconds. Training speed 770 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 10.263. Accuracy is 95.70%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 10.691. Accuracy is 86.32%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 2 seconds. Training speed 776 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 9.565. Accuracy is 94.80%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 9.898. Accuracy is 87.85%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 2 seconds. Training speed 776 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 8.671. Accuracy is 97.30%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 9.360. Accuracy is 80.23%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 2 seconds. Training speed 782 pps. Validation speed 18184 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 79.77 %, cost (ce) is 0.814\n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 633.467. Accuracy is 8.50%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 633.395. Accuracy is 10.85%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 365.843. Accuracy is 50.60%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 363.571. Accuracy is 71.30%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 2 seconds. Training speed 764 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 174.645. Accuracy is 66.80%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 174.285. Accuracy is 77.87%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 2 seconds. Training speed 770 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 71.847. Accuracy is 63.80%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 73.259. Accuracy is 57.22%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 2 seconds. Training speed 776 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 39.449. Accuracy is 60.60%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 39.110. Accuracy is 62.61%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 2 seconds. Training speed 794 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 36.329. Accuracy is 60.20%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 37.329. Accuracy is 43.96%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 2 seconds. Training speed 794 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 34.184. Accuracy is 61.80%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 33.597. Accuracy is 63.60%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 2 seconds. Training speed 794 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 28.892. Accuracy is 67.10%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 28.100. Accuracy is 73.10%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 2 seconds. Training speed 794 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 28.418. Accuracy is 66.20%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 27.830. Accuracy is 72.20%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 2 seconds. Training speed 788 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 29.081. Accuracy is 67.40%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 28.907. Accuracy is 65.50%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 2 seconds. Training speed 794 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 29.410. Accuracy is 67.20%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 29.708. Accuracy is 63.10%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 2 seconds. Training speed 788 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 25.472. Accuracy is 73.00%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 24.777. Accuracy is 82.20%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 2 seconds. Training speed 788 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 30.784. Accuracy is 69.10%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 29.955. Accuracy is 79.02%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 2 seconds. Training speed 794 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 27.267. Accuracy is 73.10%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 27.331. Accuracy is 67.46%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 2 seconds. Training speed 794 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 24.075. Accuracy is 76.90%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 23.766. Accuracy is 81.02%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 2 seconds. Training speed 788 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 29.642. Accuracy is 72.30%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 30.491. Accuracy is 67.73%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 2 seconds. Training speed 788 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 24.598. Accuracy is 77.60%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 24.557. Accuracy is 76.25%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 2 seconds. Training speed 782 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 27.204. Accuracy is 75.90%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 28.410. Accuracy is 61.21%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 2 seconds. Training speed 788 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 24.681. Accuracy is 78.50%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 24.803. Accuracy is 79.13%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 2 seconds. Training speed 788 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 23.864. Accuracy is 80.00%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 25.212. Accuracy is 63.52%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 2 seconds. Training speed 788 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 24.802. Accuracy is 77.20%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 24.287. Accuracy is 84.95%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 2 seconds. Training speed 788 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 26.263. Accuracy is 81.10%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 27.942. Accuracy is 68.15%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 2 seconds. Training speed 788 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 29.219. Accuracy is 79.80%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 31.388. Accuracy is 58.23%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 2 seconds. Training speed 782 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 25.704. Accuracy is 78.70%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 25.132. Accuracy is 86.42%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 2 seconds. Training speed 788 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 22.053. Accuracy is 87.00%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 22.335. Accuracy is 81.14%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 2 seconds. Training speed 770 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 23.988. Accuracy is 82.10%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 24.572. Accuracy is 72.05%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 2 seconds. Training speed 782 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 22.661. Accuracy is 81.50%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 23.093. Accuracy is 71.01%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 2 seconds. Training speed 782 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 23.084. Accuracy is 82.30%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 23.014. Accuracy is 82.92%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 2 seconds. Training speed 782 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 21.962. Accuracy is 84.00%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 21.842. Accuracy is 84.36%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 2 seconds. Training speed 776 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 21.777. Accuracy is 84.30%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 21.581. Accuracy is 88.26%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 2 seconds. Training speed 776 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 22.213. Accuracy is 82.50%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 22.414. Accuracy is 78.48%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 2 seconds. Training speed 776 pps. Validation speed 18184 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 76.73 %, cost (ce) is 1.221\n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 6318.079. Accuracy is 11.40%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 6318.061. Accuracy is 10.00%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 264.071. Accuracy is 11.40%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 260.880. Accuracy is 9.61%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 2 seconds. Training speed 776 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 263.254. Accuracy is 9.50%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 260.647. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 2 seconds. Training speed 788 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 239.995. Accuracy is 10.50%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 232.720. Accuracy is 9.61%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 2 seconds. Training speed 782 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 243.773. Accuracy is 9.00%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 241.635. Accuracy is 10.90%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 2 seconds. Training speed 776 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 253.920. Accuracy is 10.10%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 252.035. Accuracy is 10.64%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 2 seconds. Training speed 782 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 254.924. Accuracy is 9.70%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 257.241. Accuracy is 9.61%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 2 seconds. Training speed 782 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 257.893. Accuracy is 9.30%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 256.461. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 2 seconds. Training speed 776 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 256.713. Accuracy is 10.00%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 255.861. Accuracy is 9.61%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 2 seconds. Training speed 770 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 246.077. Accuracy is 10.50%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 242.243. Accuracy is 9.90%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 2 seconds. Training speed 782 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 259.448. Accuracy is 9.70%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 266.312. Accuracy is 10.30%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 2 seconds. Training speed 776 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 287.153. Accuracy is 10.10%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 286.417. Accuracy is 10.90%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 2 seconds. Training speed 747 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 271.564. Accuracy is 10.60%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 273.380. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 2 seconds. Training speed 782 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 252.627. Accuracy is 10.30%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 253.171. Accuracy is 9.90%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 2 seconds. Training speed 776 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 259.771. Accuracy is 10.70%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 258.932. Accuracy is 10.09%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 2 seconds. Training speed 782 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 269.511. Accuracy is 10.10%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 274.308. Accuracy is 9.15%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 2 seconds. Training speed 788 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 249.550. Accuracy is 10.00%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 249.801. Accuracy is 10.90%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 2 seconds. Training speed 788 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 256.326. Accuracy is 9.20%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 255.601. Accuracy is 9.15%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 2 seconds. Training speed 782 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 265.635. Accuracy is 10.20%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 263.850. Accuracy is 9.15%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 2 seconds. Training speed 782 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 280.399. Accuracy is 9.50%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 282.559. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 2 seconds. Training speed 741 pps. Validation speed 16951 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 251.389. Accuracy is 10.40%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 248.339. Accuracy is 9.15%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 2 seconds. Training speed 667 pps. Validation speed 15153 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 267.720. Accuracy is 11.40%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 272.379. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 2 seconds. Training speed 650 pps. Validation speed 15627 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 268.160. Accuracy is 9.00%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 273.650. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 2 seconds. Training speed 758 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 249.676. Accuracy is 10.10%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 247.460. Accuracy is 9.15%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 2 seconds. Training speed 634 pps. Validation speed 15386 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 261.436. Accuracy is 10.20%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 263.172. Accuracy is 10.64%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 2 seconds. Training speed 582 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 247.845. Accuracy is 10.30%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 242.830. Accuracy is 10.64%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 2 seconds. Training speed 690 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 262.515. Accuracy is 9.90%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 260.378. Accuracy is 9.67%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 2 seconds. Training speed 776 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 249.887. Accuracy is 10.70%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 249.191. Accuracy is 10.64%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 2 seconds. Training speed 747 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 250.509. Accuracy is 10.00%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 252.616. Accuracy is 9.61%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 2 seconds. Training speed 710 pps. Validation speed 16131 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 268.580. Accuracy is 8.50%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 266.808. Accuracy is 10.64%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 2 seconds. Training speed 695 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 252.126. Accuracy is 9.30%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 252.469. Accuracy is 9.90%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 2 seconds. Training speed 753 pps. Validation speed 17859 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 10.32 %, cost (ce) is 12.459\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import logging\n",
    "from mlp.dataset import MNISTDataProvider\n",
    "\n",
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "from mlp.dataset import MNISTDataProvider #import data provider\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateFixed, DropoutFixed, DropoutAnnealed\n",
    "\n",
    "#load the corresponding code here, and also attach scripts that run the experiments ()\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=10, max_num_batches=100, randomize=True)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "from mlp.layers import MLP, Linear, Sigmoid, Softmax #import required layer types\n",
    "from mlp.optimisers import SGDOptimiser #import the optimiser\n",
    "\n",
    "from mlp.costs import CECost #import the cost we want to use for optimisation\n",
    "from mlp.schedulers import LearningRateFixed, LearningRateExponential, LearningRateReciprocal\n",
    "\n",
    "rng = numpy.random.RandomState([2015,10,10])\n",
    "\n",
    "logger.info('Initialising data providers...')\n",
    "\n",
    "train_dp = MNISTDataProvider(dset='train', batch_size=10, max_num_batches=100, randomize=True)\n",
    "valid_dp = MNISTDataProvider(dset='valid', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "test_dp = MNISTDataProvider(dset='eval', batch_size=10000, max_num_batches=-10, randomize=False)\n",
    "\n",
    "#some hyper-parameters\n",
    "nhid = 800\n",
    "learning_rate = 0.5\n",
    "max_epochs = 30\n",
    "\n",
    "cost = CECost()\n",
    "    \n",
    "stats = []\n",
    "layer = 1\n",
    "\n",
    "# L1 parameters\n",
    "l2_weight = 0\n",
    "\n",
    "for l1_weight in [0.0001, 0.001, 0.01, 0.1]:\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "    \n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "    model.add_layer(Sigmoid(idim=784, odim=nhid, irange=0.2, rng=rng))\n",
    "    for i in xrange(1, layer):\n",
    "        logger.info(\"Stacking hidden layer (%s)\" % str(i+1))\n",
    "        model.add_layer(Sigmoid(idim=nhid, odim=nhid, irange=0.2, rng=rng))\n",
    "    model.add_layer(Softmax(idim=nhid, odim=10, rng=rng))\n",
    "\n",
    "    # define the optimiser, here stochasitc gradient descent\n",
    "    # with fixed learning rate and max_epochs\n",
    "    lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    dp_scheduler = DropoutFixed(0.5, 0.5)\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler,\n",
    "                             dp_scheduler=None,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "\n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "    \n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 6.791. Accuracy is 8.30%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 6.773. Accuracy is 10.28%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 7.076. Accuracy is 60.70%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 4.872. Accuracy is 81.40%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 2 seconds. Training speed 981 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 4.739. Accuracy is 85.70%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 4.742. Accuracy is 84.68%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 2 seconds. Training speed 981 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 4.562. Accuracy is 89.80%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 4.622. Accuracy is 88.42%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 2 seconds. Training speed 981 pps. Validation speed 16395 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 4.449. Accuracy is 92.80%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 4.658. Accuracy is 86.63%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 2 seconds. Training speed 856 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 4.372. Accuracy is 94.80%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 4.574. Accuracy is 88.82%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 2 seconds. Training speed 927 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 4.309. Accuracy is 96.40%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 4.539. Accuracy is 89.48%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 2 seconds. Training speed 962 pps. Validation speed 16131 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 4.238. Accuracy is 98.30%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 4.534. Accuracy is 89.23%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 2 seconds. Training speed 848 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 4.188. Accuracy is 99.10%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 4.495. Accuracy is 89.50%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 2 seconds. Training speed 863 pps. Validation speed 16951 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 4.147. Accuracy is 99.00%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 4.587. Accuracy is 86.28%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 2 seconds. Training speed 927 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 4.101. Accuracy is 99.40%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 4.454. Accuracy is 89.62%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 2 seconds. Training speed 963 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 4.060. Accuracy is 99.60%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 4.415. Accuracy is 89.68%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 2 seconds. Training speed 894 pps. Validation speed 16951 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 4.022. Accuracy is 99.70%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 4.395. Accuracy is 89.65%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 2 seconds. Training speed 944 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 3.984. Accuracy is 99.80%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 4.382. Accuracy is 89.06%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 2 seconds. Training speed 902 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 3.949. Accuracy is 99.90%\n",
      "INFO:mlp.optimisers:Epoch 14: Validation cost (ce) is 4.337. Accuracy is 89.43%\n",
      "INFO:mlp.optimisers:Epoch 14: Took 2 seconds. Training speed 981 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 15: Training cost (ce) is 3.913. Accuracy is 99.80%\n",
      "INFO:mlp.optimisers:Epoch 15: Validation cost (ce) is 4.308. Accuracy is 89.66%\n",
      "INFO:mlp.optimisers:Epoch 15: Took 2 seconds. Training speed 962 pps. Validation speed 16668 pps.\n",
      "INFO:mlp.optimisers:Epoch 16: Training cost (ce) is 3.877. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 16: Validation cost (ce) is 4.267. Accuracy is 89.83%\n",
      "INFO:mlp.optimisers:Epoch 16: Took 2 seconds. Training speed 944 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 17: Training cost (ce) is 3.842. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 17: Validation cost (ce) is 4.235. Accuracy is 90.01%\n",
      "INFO:mlp.optimisers:Epoch 17: Took 2 seconds. Training speed 981 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 18: Training cost (ce) is 3.808. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 18: Validation cost (ce) is 4.218. Accuracy is 89.42%\n",
      "INFO:mlp.optimisers:Epoch 18: Took 2 seconds. Training speed 991 pps. Validation speed 16951 pps.\n",
      "INFO:mlp.optimisers:Epoch 19: Training cost (ce) is 3.774. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 19: Validation cost (ce) is 4.179. Accuracy is 90.01%\n",
      "INFO:mlp.optimisers:Epoch 19: Took 2 seconds. Training speed 910 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 20: Training cost (ce) is 3.740. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 20: Validation cost (ce) is 4.148. Accuracy is 89.98%\n",
      "INFO:mlp.optimisers:Epoch 20: Took 2 seconds. Training speed 870 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 21: Training cost (ce) is 3.706. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 21: Validation cost (ce) is 4.111. Accuracy is 90.16%\n",
      "INFO:mlp.optimisers:Epoch 21: Took 2 seconds. Training speed 972 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 22: Training cost (ce) is 3.674. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 22: Validation cost (ce) is 4.083. Accuracy is 89.77%\n",
      "INFO:mlp.optimisers:Epoch 22: Took 2 seconds. Training speed 918 pps. Validation speed 16951 pps.\n",
      "INFO:mlp.optimisers:Epoch 23: Training cost (ce) is 3.640. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 23: Validation cost (ce) is 4.053. Accuracy is 90.03%\n",
      "INFO:mlp.optimisers:Epoch 23: Took 2 seconds. Training speed 981 pps. Validation speed 16951 pps.\n",
      "INFO:mlp.optimisers:Epoch 24: Training cost (ce) is 3.608. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 24: Validation cost (ce) is 4.021. Accuracy is 90.01%\n",
      "INFO:mlp.optimisers:Epoch 24: Took 2 seconds. Training speed 910 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 25: Training cost (ce) is 3.576. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 25: Validation cost (ce) is 3.993. Accuracy is 90.01%\n",
      "INFO:mlp.optimisers:Epoch 25: Took 2 seconds. Training speed 972 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 26: Training cost (ce) is 3.543. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 26: Validation cost (ce) is 3.956. Accuracy is 90.18%\n",
      "INFO:mlp.optimisers:Epoch 26: Took 2 seconds. Training speed 972 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 27: Training cost (ce) is 3.512. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 27: Validation cost (ce) is 3.927. Accuracy is 89.98%\n",
      "INFO:mlp.optimisers:Epoch 27: Took 2 seconds. Training speed 972 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 28: Training cost (ce) is 3.480. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 28: Validation cost (ce) is 3.900. Accuracy is 89.98%\n",
      "INFO:mlp.optimisers:Epoch 28: Took 2 seconds. Training speed 972 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 29: Training cost (ce) is 3.449. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 29: Validation cost (ce) is 3.872. Accuracy is 89.84%\n",
      "INFO:mlp.optimisers:Epoch 29: Took 2 seconds. Training speed 972 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 30: Training cost (ce) is 3.418. Accuracy is 100.00%\n",
      "INFO:mlp.optimisers:Epoch 30: Validation cost (ce) is 3.841. Accuracy is 90.12%\n",
      "INFO:mlp.optimisers:Epoch 30: Took 2 seconds. Training speed 963 pps. Validation speed 17859 pps.\n",
      "INFO:root:Testing the model on test set:\n",
      "INFO:root:MNIST test set accuracy is 89.26 %, cost (ce) is 0.437\n",
      "INFO:root:Training started...\n",
      "INFO:mlp.optimisers:Epoch 0: Training cost (ce) for initial model is 44.851. Accuracy is 9.70%\n",
      "INFO:mlp.optimisers:Epoch 0: Validation cost (ce) for initial model is 44.866. Accuracy is 9.54%\n",
      "INFO:mlp.optimisers:Epoch 1: Training cost (ce) is 41.818. Accuracy is 60.70%\n",
      "INFO:mlp.optimisers:Epoch 1: Validation cost (ce) is 39.569. Accuracy is 81.28%\n",
      "INFO:mlp.optimisers:Epoch 1: Took 2 seconds. Training speed 972 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 2: Training cost (ce) is 36.109. Accuracy is 83.40%\n",
      "INFO:mlp.optimisers:Epoch 2: Validation cost (ce) is 36.100. Accuracy is 83.91%\n",
      "INFO:mlp.optimisers:Epoch 2: Took 2 seconds. Training speed 972 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 3: Training cost (ce) is 32.953. Accuracy is 86.90%\n",
      "INFO:mlp.optimisers:Epoch 3: Validation cost (ce) is 33.019. Accuracy is 85.88%\n",
      "INFO:mlp.optimisers:Epoch 3: Took 2 seconds. Training speed 953 pps. Validation speed 17546 pps.\n",
      "INFO:mlp.optimisers:Epoch 4: Training cost (ce) is 30.065. Accuracy is 90.60%\n",
      "INFO:mlp.optimisers:Epoch 4: Validation cost (ce) is 30.199. Accuracy is 86.27%\n",
      "INFO:mlp.optimisers:Epoch 4: Took 2 seconds. Training speed 963 pps. Validation speed 16668 pps.\n",
      "INFO:mlp.optimisers:Epoch 5: Training cost (ce) is 27.439. Accuracy is 93.00%\n",
      "INFO:mlp.optimisers:Epoch 5: Validation cost (ce) is 27.602. Accuracy is 87.68%\n",
      "INFO:mlp.optimisers:Epoch 5: Took 2 seconds. Training speed 953 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 6: Training cost (ce) is 25.044. Accuracy is 95.30%\n",
      "INFO:mlp.optimisers:Epoch 6: Validation cost (ce) is 25.246. Accuracy is 88.47%\n",
      "INFO:mlp.optimisers:Epoch 6: Took 2 seconds. Training speed 962 pps. Validation speed 16395 pps.\n",
      "INFO:mlp.optimisers:Epoch 7: Training cost (ce) is 22.978. Accuracy is 93.60%\n",
      "INFO:mlp.optimisers:Epoch 7: Validation cost (ce) is 23.195. Accuracy is 87.78%\n",
      "INFO:mlp.optimisers:Epoch 7: Took 2 seconds. Training speed 788 pps. Validation speed 16668 pps.\n",
      "INFO:mlp.optimisers:Epoch 8: Training cost (ce) is 21.051. Accuracy is 95.70%\n",
      "INFO:mlp.optimisers:Epoch 8: Validation cost (ce) is 21.320. Accuracy is 87.07%\n",
      "INFO:mlp.optimisers:Epoch 8: Took 2 seconds. Training speed 856 pps. Validation speed 16951 pps.\n",
      "INFO:mlp.optimisers:Epoch 9: Training cost (ce) is 19.251. Accuracy is 97.00%\n",
      "INFO:mlp.optimisers:Epoch 9: Validation cost (ce) is 19.558. Accuracy is 87.44%\n",
      "INFO:mlp.optimisers:Epoch 9: Took 2 seconds. Training speed 972 pps. Validation speed 18184 pps.\n",
      "INFO:mlp.optimisers:Epoch 10: Training cost (ce) is 17.652. Accuracy is 97.50%\n",
      "INFO:mlp.optimisers:Epoch 10: Validation cost (ce) is 17.992. Accuracy is 86.39%\n",
      "INFO:mlp.optimisers:Epoch 10: Took 2 seconds. Training speed 807 pps. Validation speed 16395 pps.\n",
      "INFO:mlp.optimisers:Epoch 11: Training cost (ce) is 16.251. Accuracy is 96.10%\n",
      "INFO:mlp.optimisers:Epoch 11: Validation cost (ce) is 16.555. Accuracy is 87.59%\n",
      "INFO:mlp.optimisers:Epoch 11: Took 2 seconds. Training speed 878 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 12: Training cost (ce) is 14.890. Accuracy is 98.20%\n",
      "INFO:mlp.optimisers:Epoch 12: Validation cost (ce) is 15.171. Accuracy is 89.27%\n",
      "INFO:mlp.optimisers:Epoch 12: Took 2 seconds. Training speed 886 pps. Validation speed 17243 pps.\n",
      "INFO:mlp.optimisers:Epoch 13: Training cost (ce) is 13.751. Accuracy is 97.30%\n",
      "INFO:mlp.optimisers:Epoch 13: Validation cost (ce) is 14.090. Accuracy is 87.05%\n",
      "INFO:mlp.optimisers:Epoch 13: Took 2 seconds. Training speed 963 pps. Validation speed 17859 pps.\n",
      "INFO:mlp.optimisers:Epoch 14: Training cost (ce) is 12.729. Accuracy is 95.60%\n"
     ]
    }
   ],
   "source": [
    "# L2 parameters\n",
    "\n",
    "l1_weight = 0\n",
    "\n",
    "for l2_weight in [0.0001, 0.001, 0.01, 0.1]:\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "    \n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "    model.add_layer(Sigmoid(idim=784, odim=nhid, irange=0.2, rng=rng))\n",
    "    for i in xrange(1, layer):\n",
    "        logger.info(\"Stacking hidden layer (%s)\" % str(i+1))\n",
    "        model.add_layer(Sigmoid(idim=nhid, odim=nhid, irange=0.2, rng=rng))\n",
    "    model.add_layer(Softmax(idim=nhid, odim=10, rng=rng))\n",
    "\n",
    "    # define the optimiser, here stochasitc gradient descent\n",
    "    # with fixed learning rate and max_epochs\n",
    "    lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    dp_scheduler = DropoutFixed(0.5, 0.5)\n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler,\n",
    "                             dp_scheduler=None,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "\n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "    \n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# annealed and fixed dropout\n",
    "\n",
    "dp_fixed_scheduler = DropoutFixed(0.5, 0.5)\n",
    "dp_annealed_scheduler = DropoutAnnealed(0.5, 0.5)\n",
    "dp_schedulers = [dp_fixed_scheduler, dp_annealed_scheduler]\n",
    "l1_weight = 0.0\n",
    "l2_weight = 0.0    \n",
    "    \n",
    "for dp_scheduler in dp_schedulers:\n",
    "\n",
    "    train_dp.reset()\n",
    "    valid_dp.reset()\n",
    "    test_dp.reset()\n",
    "    \n",
    "    #define the model\n",
    "    model = MLP(cost=cost)\n",
    "    model.add_layer(Sigmoid(idim=784, odim=nhid, irange=0.2, rng=rng))\n",
    "    for i in xrange(1, layer):\n",
    "        logger.info(\"Stacking hidden layer (%s)\" % str(i+1))\n",
    "        model.add_layer(Sigmoid(idim=nhid, odim=nhid, irange=0.2, rng=rng))\n",
    "    model.add_layer(Softmax(idim=nhid, odim=10, rng=rng))\n",
    "\n",
    "    # define the optimiser, here stochasitc gradient descent\n",
    "    # with fixed learning rate and max_epochs\n",
    "    lr_scheduler = LearningRateFixed(learning_rate=learning_rate, max_epochs=max_epochs)\n",
    "    \n",
    "    optimiser = SGDOptimiser(lr_scheduler=lr_scheduler,\n",
    "                             dp_scheduler=dp_scheduler,\n",
    "                             l1_weight=l1_weight, \n",
    "                             l2_weight=l2_weight)\n",
    "\n",
    "    logger.info('Training started...')\n",
    "    tr_stats, valid_stats = optimiser.train(model, train_dp, valid_dp)\n",
    "\n",
    "    logger.info('Testing the model on test set:')\n",
    "    tst_cost, tst_accuracy = optimiser.validate(model, test_dp)\n",
    "    logger.info('MNIST test set accuracy is %.2f %%, cost (%s) is %.3f'%(tst_accuracy*100., cost.get_name(), tst_cost))\n",
    "    \n",
    "    stats.append((tr_stats, valid_stats, (tst_cost, tst_accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# arranging the data for plotting\n",
    "test_results = [stat[2] for stat in stats]\n",
    "test_ce_costs = [test_result[0] for test_result in test_results]\n",
    "test_accuracies = [test_result[1] for test_result in test_results]\n",
    "\n",
    "fixed_training_ce_costs = [test_result[1] for test_result in stats[0][1]]\n",
    "exponential_training_ce_costs = [test_result[1] for test_result in stats[1][1]]\n",
    "reciprocal_training_ce_costs = [test_result[1] for test_result in stats[2][1]]\n",
    "\n",
    "fixed_training_accuracies = [test_result[1] for test_result in stats[0][1]]\n",
    "exponential_training_accuracies = [test_result[1] for test_result in stats[1][1]]\n",
    "reciprocal_training_accuracies = [test_result[1] for test_result in stats[2][1]]\n",
    "\n",
    "epochs = xrange(0,31)\n",
    "names = ['fixed','exponential','reciprocal']\n",
    "\n",
    "# training plot\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(fixed_training_accuracies, epochs, label=\"fixed\")\n",
    "plt.plot(exponential_training_accuracies, epochs, label=\"exponential\")\n",
    "plt.plot(reciprocal_training_accuracies, epochs, label=\"reciprocal\")\n",
    "\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('Training accuracy (%)')\n",
    "plt.title('Fixed, exponential, and reciprocal learning rate scheduler test accuracy')\n",
    "plt.legend(loc='left')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.savefig(\"pictures/test.png\")\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "width = .25\n",
    "ind = numpy.arange(len(test_accuracies))\n",
    "plt.bar(ind, test_accuracies)\n",
    "plt.xticks(ind + width / 2, names)\n",
    "\n",
    "plt.xlabel('Different learning rate schedulers')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Fixed, exponential, and reciprocal learning rate scheduler test accuracy')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"pictures/test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Experiments with pretraining (15 marks)\n",
    "\n",
    "Implement pretraining of multi-layer networks with autoencoders, denoising autoencoders, and using  layer-by-layer cross-entropy training.  \n",
    "\n",
    "Implementation tip: You could add the corresponding methods to `optimiser`, namely, `pretrain()` and `pretrain_epoch()`, for autoencoders. Simiilarly, `pretrain_discriminative()` and `pretrain_epoch_discriminative()` for cross-entropy layer-by-layer pretraining. Of course, you can modify any other necessary pieces, but include all the modified fragments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Experiments with data augmentation (5 marks)\n",
    "\n",
    "Using the standard MNIST training data, generate some augmented training examples (for example, using noise or rotation). Perform experiments on using this expanded training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 - State of the art (5 marks)\n",
    "\n",
    "Using any techniques you have learnt so far (combining any number of them), build and train the best model you can (no other constraints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 2. Convolutional Neural Networks (55 marks)\n",
    "\n",
    "In this part of the coursework, you are required to implement deep convolutional networks.  This includes code for forward prop, back prop, and weight updates for convolutional and max-pooling layers, and should support the stacking of convolutional + pooling layers.  You should implement all the parts relating to the convolutional layer in the mlp/conv.py module; if you decide to implement some routines in cython, keep them in mlp/conv.pyx). Attach both files in this notebook.\n",
    "\n",
    "Implementation tips: Look at [lecture 7](http://www.inf.ed.ac.uk/teaching/courses/mlp/2015/mlp07-cnn.pdf) and [lecture 8](http://www.inf.ed.ac.uk/teaching/courses/mlp/2015/mlp08-cnn2.pdf), and the introductory tutorial, [06_MLP_Coursework2_Introduction.ipynb](https://github.com/CSTR-Edinburgh/mlpractical/blob/master/06_MLP_Coursework2_Introduction.ipynb)\n",
    "\n",
    "### Task 6 -  Implement convolutional layer (20 marks)\n",
    "\n",
    "Implement linear convolutional layer, and then extend to sigmoid and ReLU transfer functions (do it in a similar way to fully-connected layers). Include all relevant code.  It is recommended that you first implement in the naive way with nested loops (python and/or cython);  optionally you may then implement in a vectorised way in numpy.  Include logs for each way you implement the convolutional layer, as timings for different implementations are of interest.  Include all relevant code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 7 - Implement max-pooling layer (10 marks)\n",
    "\n",
    "Implement a max-pooling layer. Non-overlapping pooling (which was assumed in the lecture presentation) is required. You may also implement a more generic solution with striding as well. Include all relevant code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 - Experiments with convolutional networks (25 marks)\n",
    "\n",
    "Construct convolutional networks with a softmax output layer and a single fully connected hidden layer. Your first experiments should use one convolutional+pooling layer.  As a default use convolutional kernels of dimension 5x5 (stride 1) and pooling regions of 2x2 (stride 2, hence non-overlapping).\n",
    "\n",
    "*  Implement and test a convolutional network with 1 feature map\n",
    "*  Implement and test a convolutional network with 5 feature maps\n",
    "\n",
    "Explore convolutional networks with two convolutional layers, by implementing, training, and evaluating a network with two convolutional+maxpooling layers with 5 feature maps in the first convolutional layer,  and 10 feature maps in the second convolutional layer.\n",
    "\n",
    "Carry out further experiments to optimise the convolutional network architecture (you could explore kernel sizes and strides, number of feature maps, sizes and strides of pooling operator, etc. - it is up to you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**This is the end of coursework 2.**\n",
    "\n",
    "Please remember to save your notebook, and submit your notebook following the instructions at the top.  Please make sure that you have executed all the code cells when you submit the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
